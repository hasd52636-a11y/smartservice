import React, { useState, useRef, useEffect } from 'react';
import { useParams } from 'react-router-dom';
import { ProductProject, AIProvider, KnowledgeType } from '../types';
import { 
  Mic, Send, Camera, Volume2, Video, X, Sparkles, Globe, Waves, 
  PlayCircle, FileText, ChevronRight, Pencil, Circle, ArrowRight, Highlighter,
  Upload, Image as ImageIcon, AlertCircle, CheckCircle, Loader2
} from 'lucide-react';
import { aiService, RealtimeCallback, Annotation } from '../services/aiService';
import { projectService } from '../services/projectService';

const UserPreview: React.FC<{ projects?: ProductProject[]; projectId?: string }> = ({ projects, projectId: propProjectId }) => {
  const { id } = useParams();
  const projectId = propProjectId || id;
  const [project, setProject] = useState<ProductProject | null>(null);
  const [projectLoading, setProjectLoading] = useState(true);
  const [projectError, setProjectError] = useState<string>('');
  
  // æ‰€æœ‰çŠ¶æ€åˆå§‹åŒ–ç§»åˆ°ç»„ä»¶é¡¶å±‚
  const [messages, setMessages] = useState<{role: 'user' | 'assistant', text: string, image?: string}[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [isTyping, setIsTyping] = useState(false);
  const [activeVideo, setActiveVideo] = useState<string | null>(null);
  const [streamingMessage, setStreamingMessage] = useState<string | null>(null);
  const [streamingId, setStreamingId] = useState<number | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [isVoiceActive, setIsVoiceActive] = useState(false); // è¯­éŸ³æ˜¯å¦æ´»è·ƒ
  const [silenceTimer, setSilenceTimer] = useState<NodeJS.Timeout | null>(null); // é™éŸ³å®šæ—¶å™¨
  const [isOcrProcessing, setIsOcrProcessing] = useState(false);
  const [ocrResult, setOcrResult] = useState<string>('');
  const [ocrImage, setOcrImage] = useState<string | null>(null);
  const [ocrMessage, setOcrMessage] = useState({ type: 'info' as 'info' | 'success' | 'error', text: '' });
  const [isVideoChatActive, setIsVideoChatActive] = useState(false);
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [isVideoOn, setIsVideoOn] = useState(true);
  const [isAudioOn, setIsAudioOn] = useState(true);
  const [isConnected, setIsConnected] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState('disconnected');
  const [avatarState, setAvatarState] = useState({
    expression: 'neutral',
    gesture: 'idle',
    speech: '',
    mouthShape: 'closed'
  });
  const [annotations, setAnnotations] = useState<Annotation[]>([]);
  const [currentAnnotationType, setCurrentAnnotationType] = useState<'arrow' | 'circle' | 'text' | 'highlight'>('arrow');
  const [isAddingAnnotation, setIsAddingAnnotation] = useState(false);
  
  // References
  const scrollRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const ocrFileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationFrameRef = useRef<number>();
  const videoStreamRef = useRef<MediaStream | null>(null);

  // æ¸…ç†è§†é¢‘èŠå¤©å‡½æ•°ï¼ˆç§»åˆ°æœ€å‰é¢ï¼Œç¡®ä¿åœ¨useEffectä¸­è¢«è°ƒç”¨æ—¶å·²å®šä¹‰ï¼‰
  const cleanupVideoChat = () => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = undefined;
    }
    
    if (videoStreamRef.current) {
      videoStreamRef.current.getTracks().forEach(track => track.stop());
      videoStreamRef.current = null;
    }
    
    aiService.disconnectFromRealtime();
    setIsVideoChatActive(false);
    setVideoStream(null);
    setIsConnected(false);
    setConnectionStatus('disconnected');
    setAnnotations([]);
  };

  // ä»æœåŠ¡ç«¯åŠ è½½é¡¹ç›®æ•°æ®
  useEffect(() => {
    const loadProject = async () => {
      if (!projectId) {
        setProjectError('æ— æ•ˆçš„é¡¹ç›®ID');
        setProjectLoading(false);
        return;
      }

      try {
        setProjectLoading(true);
        setProjectError('');
        
        // éªŒè¯é¡¹ç›®IDå¹¶è·å–é¡¹ç›®æ•°æ®
        const validation = await projectService.validateProjectId(projectId);
        
        if (!validation.valid) {
          setProjectError(validation.error || 'é¡¹ç›®éªŒè¯å¤±è´¥');
          setProjectLoading(false);
          return;
        }

        const validatedProject = validation.project!;
        
        // è®°å½•ç”¨æˆ·è®¿é—®ï¼ˆåŒ¿åç»Ÿè®¡ï¼‰
        await projectService.logUserAccess(projectId, {
          timestamp: new Date().toISOString(),
          userAgent: navigator.userAgent,
          referrer: document.referrer
        });
        
        // ç›´æ¥æ›´æ–°çŠ¶æ€ï¼Œé¿å…setTimeoutå¯èƒ½å¯¼è‡´çš„é—®é¢˜
        setProject(validatedProject);
        
        // åˆå§‹åŒ–messagesçŠ¶æ€ - ä½¿ç”¨é¡¹ç›®é…ç½®çš„æ¬¢è¿è¯­æˆ–é»˜è®¤æ¬¢è¿è¯­
        const welcomeMessage = validatedProject.config.welcomeMessage || 
          `æ‚¨å¥½ï¼æˆ‘æ˜¯ ${validatedProject.name} çš„æ™ºèƒ½å”®åå®¢æœåŠ©æ‰‹ ğŸ¤–

æˆ‘å¯ä»¥å¸®æ‚¨è§£å†³ï¼š
â€¢ äº§å“ä½¿ç”¨é—®é¢˜
â€¢ å®‰è£…æŒ‡å¯¼
â€¢ æ•…éšœæ’æŸ¥
â€¢ ç»´æŠ¤ä¿å…»

è¯·æè¿°æ‚¨é‡åˆ°çš„é—®é¢˜ï¼Œæˆ–ä¸Šä¼ ç›¸å…³å›¾ç‰‡ï¼Œæˆ‘ä¼šåŸºäºäº§å“çŸ¥è¯†åº“ä¸ºæ‚¨æä¾›ä¸“ä¸šè§£ç­”ã€‚`;
        setMessages([
          { 
            role: 'assistant', 
            text: welcomeMessage 
          }
        ]);
        
        setProjectLoading(false);
      } catch (error) {
        console.error('åŠ è½½é¡¹ç›®å¤±è´¥:', error);
        setProjectError('åŠ è½½é¡¹ç›®ä¿¡æ¯å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•');
        setProjectLoading(false);
      }
    };

    loadProject();
  }, [projectId]);

  // åˆå§‹åŒ–AIæœåŠ¡ï¼ˆé™é»˜åŠ è½½å•†å®¶é¢„é…ç½®çš„APIå¯†é’¥ï¼‰
  useEffect(() => {
    const initializeAIService = () => {
      // å°è¯•ä»localStorageåŠ è½½å•†å®¶é¢„é…ç½®çš„APIå¯†é’¥
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }
      // å¦‚æœæ²¡æœ‰localStorageä¸­çš„å¯†é’¥ï¼ŒaiServiceä¼šè‡ªåŠ¨ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å¯†é’¥
    };
    
    initializeAIService();
  }, []);

  // æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    if (scrollRef.current) scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
  }, [messages, isTyping]);

  // æ¸…ç†è§†é¢‘èŠå¤©
  useEffect(() => {
    return () => {
      cleanupVideoChat();
    };
  }, []);

  // é¡¹ç›®åŠ è½½ä¸­
  if (projectLoading) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-[#1a103d] to-[#2d1b69] flex flex-col items-center justify-center p-6">
        <div className="max-w-md w-full bg-white rounded-[3rem] border-2 border-violet-500/30 p-8 shadow-2xl">
          <div className="text-center">
            <div className="w-20 h-20 bg-violet-500/20 text-violet-600 rounded-full flex items-center justify-center mx-auto mb-6">
              <Loader2 className="animate-spin" size={40} />
            </div>
            <h1 className="text-2xl font-black text-violet-800 mb-4">æ­£åœ¨è¿æ¥æœåŠ¡</h1>
            <p className="text-slate-600">æ­£åœ¨éªŒè¯äºŒç»´ç å¹¶åŠ è½½äº§å“ä¿¡æ¯...</p>
          </div>
        </div>
      </div>
    );
  }
  
  // å¤„ç†é¡¹ç›®ä¸å­˜åœ¨æˆ–éªŒè¯å¤±è´¥çš„æƒ…å†µ
  if (!project || projectError) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-[#1a103d] to-[#2d1b69] flex flex-col items-center justify-center p-6">
        <div className="max-w-md w-full bg-white rounded-[3rem] border-2 border-amber-500/30 p-8 shadow-2xl">
          <div className="text-center mb-8">
            <div className="w-20 h-20 bg-purple-500/20 text-purple-600 rounded-full flex items-center justify-center mx-auto mb-6">
              <AlertCircle size={40} />
            </div>
            <h1 className="text-2xl font-black text-purple-800 mb-4">æœåŠ¡æš‚æ—¶ä¸å¯ç”¨</h1>
            <p className="text-slate-600 text-center mb-4">
              {projectError || 'æ‰¾ä¸åˆ°å¯¹åº”çš„é¡¹ç›®ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥äºŒç»´ç æ˜¯å¦æ­£ç¡®ã€‚'}
            </p>
            <div className="bg-purple-50 border border-purple-200 rounded-xl p-4 mb-6">
              <p className="text-sm text-purple-800">
                <strong>å¯èƒ½çš„åŸå› ï¼š</strong><br/>
                â€¢ äºŒç»´ç å·²è¿‡æœŸæˆ–æ— æ•ˆ<br/>
                â€¢ äº§å“æœåŠ¡å·²æš‚åœ<br/>
                â€¢ ç½‘ç»œè¿æ¥é—®é¢˜<br/>
                â€¢ è¯·è”ç³»ä¸­æ’åˆ›ä¸–æŠ€æœ¯æ”¯æŒ
              </p>
            </div>
          </div>
          
          <div className="space-y-4 mb-8">
            <h2 className="text-lg font-black text-purple-800 mb-4">è”ç³»æˆ‘ä»¬</h2>
            
            <div className="flex items-center gap-4 p-4 bg-purple-50 rounded-xl border border-purple-200">
              <div className="w-10 h-10 bg-purple-100 text-purple-600 rounded-full flex items-center justify-center">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M22 16.92v3a2 2 0 0 1-2.18 2 19.79 19.79 0 0 1-8.63-3.07 19.5 19.5 0 0 1-6-6 19.79 19.79 0 0 1-3.07-8.67A2 2 0 0 1 4.11 2h3a2 2 0 0 1 2 1.72 12.84 12.84 0 0 0 .7 2.81 2 2 0 0 1-.45 2.11L8.09 9.91a16 16 0 0 0 6 6l1.27-1.27a2 2 0 0 1 2.11-.45 12.84 12.84 0 0 0 2.81.7A2 2 0 0 1 22 16.92z"></path></svg>
              </div>
              <div className="flex-1">
                <p className="text-xs font-black text-purple-600 uppercase tracking-widest">ä¸­æ’åˆ›ä¸–æŠ€æœ¯æ”¯æŒ</p>
                <p className="text-purple-900 font-bold">400-888-6666</p>
              </div>
            </div>
            
            <div className="flex items-center gap-4 p-4 bg-purple-50 rounded-xl border border-purple-200">
              <div className="w-10 h-10 bg-purple-100 text-purple-600 rounded-full flex items-center justify-center">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
              </div>
              <div className="flex-1">
                <p className="text-xs font-black text-purple-600 uppercase tracking-widest">å®˜æ–¹ç½‘ç«™</p>
                <p className="text-purple-900 font-bold">www.aivirtualservice.com</p>
              </div>
            </div>
            
            <div className="flex items-center gap-4 p-4 bg-purple-50 rounded-xl border border-purple-200">
              <div className="w-10 h-10 bg-purple-100 text-purple-600 rounded-full flex items-center justify-center">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path></svg>
              </div>
              <div className="flex-1">
                <p className="text-xs font-black text-purple-600 uppercase tracking-widest">å¾®ä¿¡å…¬ä¼—å·</p>
                <p className="text-purple-900 font-bold">AIè™šæ‹Ÿå®¢æœåŠ©æ‰‹</p>
              </div>
            </div>
          </div>
          
          <div className="border-t border-purple-200 pt-6">
            <h3 className="text-sm font-black text-purple-800 mb-3">å…¬å¸ä¿¡æ¯</h3>
            <p className="text-slate-600 text-sm mb-2">å…¬å¸åç§°ï¼šæ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸</p>
            <p className="text-slate-600 text-sm">åœ°å€ï¼šåŒ—äº¬å¸‚æµ·æ·€åŒºç§‘æŠ€å›­åŒº88å·æ™ºèƒ½å¤§å¦15å±‚</p>
          </div>
        </div>
      </div>
    );
  }

  // Video chat functions
  const toggleVideoChat = async () => {
    if (isVideoChatActive) {
      cleanupVideoChat();
    } else {
      await initializeVideoChat();
    }
  };

  const initializeVideoChat = async () => {
    try {
      // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }
      
      // Request camera and microphone permissions
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 }
        },
        audio: true
      });
      
      setVideoStream(stream);
      videoStreamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
      
      // Connect to GLM-Realtime (å¦‚æœæœ‰APIå¯†é’¥çš„è¯)
      if (savedApiKey) {
        const connected = await connectToRealtime();
        
        if (connected) {
          // Start render loop for annotations
          startRenderLoop();
          setIsVideoChatActive(true);
        } else {
          console.error('GLM-Realtimeè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è§†é¢‘åŠŸèƒ½');
          setMessages(prev => [...prev, { role: 'assistant', text: 'è§†é¢‘èŠå¤©å·²å¯åŠ¨ï¼Œä½†AIå®æ—¶åŠŸèƒ½éœ€è¦é…ç½®ã€‚æ‚¨å¯ä»¥ä½¿ç”¨åŸºç¡€è§†é¢‘åŠŸèƒ½ã€‚' }]);
          setIsVideoChatActive(true);
        }
      } else {
        setMessages(prev => [...prev, { role: 'assistant', text: 'è§†é¢‘èŠå¤©å·²å¯åŠ¨ã€‚AIå®æ—¶åŠŸèƒ½éœ€è¦é…ç½®ï¼Œå½“å‰å¯ä½¿ç”¨åŸºç¡€è§†é¢‘åŠŸèƒ½ã€‚' }]);
        setIsVideoChatActive(true);
      }
    } catch (error) {
      console.error('Failed to initialize video chat:', error);
      let errorMessage = 'æ— æ³•è®¿é—®æ‘„åƒå¤´æˆ–éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®ã€‚';
      if (error instanceof Error) {
        if (error.message.includes('Permission denied')) {
          errorMessage = 'æ‘„åƒå¤´æˆ–éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®ã€‚';
        } else if (error.message.includes('NotFoundError')) {
          errorMessage = 'æœªæ‰¾åˆ°æ‘„åƒå¤´æˆ–éº¦å…‹é£è®¾å¤‡ã€‚';
        } else {
          errorMessage = `è§†é¢‘åˆå§‹åŒ–å¤±è´¥: ${error.message}`;
        }
      }
      setMessages(prev => [...prev, { role: 'assistant', text: errorMessage }]);
    }
  };

  const connectToRealtime = async (): Promise<boolean> => {
    return new Promise((resolve) => {
      const callback: RealtimeCallback = (data, type) => {
        switch (type) {
          case 'status':
            setConnectionStatus(data.status || 'disconnected');
            setIsConnected(data.status === 'connected');
            if (data.status === 'connected') {
              resolve(true);
            } else if (data.error) {
              console.error('GLM-Realtimeè¿æ¥é”™è¯¯:', data.error);
              resolve(false);
            }
            break;
          case 'text':
            if (data.type === 'content_part_done') {
              // Content part completed
            } else if (data.type === 'function_call_done') {
              // Function call completed
            } else if (data.text) {
              setMessages(prev => [...prev, { role: 'assistant', text: data.text }]);
              
              // Update avatar state
              setAvatarState(prev => ({
                ...prev,
                speech: data.text,
                mouthShape: 'talking',
                expression: 'happy'
              }));
              
              // Reset avatar state after 3 seconds
              setTimeout(() => {
                setAvatarState(prev => ({
                  ...prev,
                  mouthShape: 'closed',
                  expression: 'neutral'
                }));
              }, 3000);
            }
            break;
          case 'annotation':
            handleAnnotationUpdate(data);
            break;
          case 'audio':
            handleAudioData(data);
            break;
          case 'video':
            handleVideoData(data);
            break;
        }
      };
      
      aiService.connectToRealtime(callback).then(success => {
        resolve(success);
      }).catch(error => {
        console.error('GLM-Realtimeè¿æ¥å¼‚å¸¸:', error);
        resolve(false);
      });
    });
  };

  const startRenderLoop = () => {
    const render = () => {
      if (canvasRef.current && videoRef.current) {
        const canvas = canvasRef.current;
        const ctx = canvas.getContext('2d');
        if (ctx) {
          // Clear canvas
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          
          // Draw annotations
          drawAnnotations(ctx);
        }
      }
      animationFrameRef.current = requestAnimationFrame(render);
    };
    
    animationFrameRef.current = requestAnimationFrame(render);
  };

  const drawAnnotations = (ctx: CanvasRenderingContext2D) => {
    annotations.forEach(annotation => {
      ctx.save();
      ctx.strokeStyle = annotation.color;
      ctx.fillStyle = annotation.color;
      ctx.lineWidth = 2;
      
      switch (annotation.type) {
        case 'arrow':
          drawArrow(ctx, annotation);
          break;
        case 'circle':
          drawCircle(ctx, annotation);
          break;
        case 'text':
          drawText(ctx, annotation);
          break;
        case 'highlight':
          drawHighlight(ctx, annotation);
          break;
      }
      
      ctx.restore();
    });
  };

  const drawArrow = (ctx: CanvasRenderingContext2D, annotation: Annotation) => {
    const { position, size } = annotation;
    ctx.beginPath();
    ctx.moveTo(position.x, position.y);
    ctx.lineTo(position.x + size.width, position.y + size.height);
    ctx.stroke();
    
    // Draw arrow head
    const angle = Math.atan2(size.height, size.width);
    const arrowLength = 15;
    ctx.beginPath();
    ctx.moveTo(position.x + size.width, position.y + size.height);
    ctx.lineTo(
      position.x + size.width - arrowLength * Math.cos(angle - Math.PI / 6),
      position.y + size.height - arrowLength * Math.sin(angle - Math.PI / 6)
    );
    ctx.moveTo(position.x + size.width, position.y + size.height);
    ctx.lineTo(
      position.x + size.width - arrowLength * Math.cos(angle + Math.PI / 6),
      position.y + size.height - arrowLength * Math.sin(angle + Math.PI / 6)
    );
    ctx.stroke();
  };

  const drawCircle = (ctx: CanvasRenderingContext2D, annotation: Annotation) => {
    const { position, size } = annotation;
    ctx.beginPath();
    ctx.arc(position.x, position.y, Math.max(size.width, size.height) / 2, 0, Math.PI * 2);
    ctx.stroke();
  };

  const drawText = (ctx: CanvasRenderingContext2D, annotation: Annotation) => {
    const { position, content } = annotation;
    ctx.font = '16px Arial';
    ctx.fillStyle = annotation.color;
    ctx.fillText(content, position.x, position.y);
  };

  const drawHighlight = (ctx: CanvasRenderingContext2D, annotation: Annotation) => {
    const { position, size } = annotation;
    ctx.fillStyle = `${annotation.color}40`; // Semi-transparent
    ctx.fillRect(position.x, position.y, size.width, size.height);
  };

  const handleAnnotationUpdate = (data: any) => {
    switch (data.action) {
      case 'add':
        setAnnotations(prev => [...prev, data.annotation]);
        break;
      case 'update':
        setAnnotations(prev => prev.map(a => a.id === data.id ? { ...a, ...data.updates } : a));
        break;
      case 'delete':
        setAnnotations(prev => prev.filter(a => a.id !== data.id));
        break;
    }
  };

  const handleAudioData = (data: any) => {
    if (data.audio) {
      try {
        const audio = new Audio(`data:audio/wav;base64,${data.audio}`);
        audio.play();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    }
  };

  const handleVideoData = (data: any) => {
    // Handle video data from server
  };

  const toggleVideo = () => {
    if (videoStream) {
      const videoTracks = videoStream.getVideoTracks();
      videoTracks.forEach(track => {
        track.enabled = !isVideoOn;
      });
      setIsVideoOn(!isVideoOn);
    }
  };

  const toggleAudio = () => {
    if (videoStream) {
      const audioTracks = videoStream.getAudioTracks();
      audioTracks.forEach(track => {
        track.enabled = !isAudioOn;
      });
      setIsAudioOn(!isAudioOn);
    }
  };

  const addAnnotation = (type: 'arrow' | 'circle' | 'text' | 'highlight', content: string = '') => {
    const newAnnotation = aiService.addAnnotation({
      type,
      position: { x: 100, y: 100 },
      size: { width: 100, height: 50 },
      content: content || 'æ ‡æ³¨å†…å®¹',
      color: '#FF5722'
    });
    
    if (newAnnotation) {
      setAnnotations(prev => [...prev, newAnnotation]);
    }
  };

  const handleSend = async (text?: string, image?: string) => {
    const msgText = text || inputValue;
    if (!msgText && !image) {
      return;
    }
    if (!project) {
      console.error('é¡¹ç›®ä¸å­˜åœ¨ï¼Œæ— æ³•å¤„ç†æ¶ˆæ¯');
      return;
    }

    try {
      // ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ç•Œé¢
      const userMessage = { role: 'user' as const, text: msgText, image };
      setMessages(prev => [...prev, userMessage]);
      setInputValue('');
      setIsTyping(true);

      // ç®€åŒ–å¤„ç†é€»è¾‘ï¼Œè®©AIæœåŠ¡è‡ªåŠ¨å¤„ç†APIå¯†é’¥å’Œå›é€€é€»è¾‘
      if (image) {
        if (!project.config.multimodalEnabled) {
          setMessages(prev => [...prev, { role: 'assistant', text: "å¤šæ¨¡æ€åˆ†æåŠŸèƒ½å·²ç¦ç”¨ï¼Œæ— æ³•åˆ†æå›¾ç‰‡å†…å®¹ã€‚" }]);
        } else {
          try {
            // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
            const savedApiKey = localStorage.getItem('zhipuApiKey');
            if (savedApiKey) {
              aiService.setZhipuApiKey(savedApiKey);
            }
            
            // å›¾ç‰‡åˆ†æ - AIæœåŠ¡ä¼šè‡ªåŠ¨å¤„ç†APIå¯†é’¥ç¼ºå¤±çš„æƒ…å†µ
            const response = await aiService.analyzeInstallation(image, project.config.visionPrompt, project.config.provider);
            setMessages(prev => [...prev, { role: 'assistant', text: response }]);
          } catch (error) {
            console.error('å›¾ç‰‡åˆ†æå¤±è´¥:', error);
            setMessages(prev => [...prev, { role: 'assistant', text: 'å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚' }]);
          }
        }
      } else {
        // ç¡®ä¿çŸ¥è¯†åº“å­˜åœ¨
        const knowledgeBase = project.knowledgeBase || [];

        try {
          // è®¾ç½®APIå¯†é’¥ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
          const savedApiKey = localStorage.getItem('zhipuApiKey');
          if (savedApiKey) {
            aiService.setZhipuApiKey(savedApiKey);
          }
          
          // å¯¹äºæ–‡æœ¬æ¶ˆæ¯ï¼Œä½¿ç”¨æµå¼è¾“å‡º
          const newMessageId = messages.length + 1;
          setStreamingId(newMessageId);
          setStreamingMessage('');

          // æµå¼å›è°ƒå‡½æ•°
          let accumulatedMessage = '';
          let lastUpdateTime = 0;
          const UPDATE_INTERVAL = 100; // é™åˆ¶æ›´æ–°é¢‘ç‡ï¼Œé¿å…é¢‘ç¹æ¸²æŸ“
          
          const streamCallback = (chunk: string, isDone: boolean) => {
            try {
              if (chunk) {
                accumulatedMessage += chunk;
                
                // é™åˆ¶æ›´æ–°é¢‘ç‡ï¼Œé¿å…é¢‘ç¹æ¸²æŸ“
                const now = Date.now();
                if (now - lastUpdateTime > UPDATE_INTERVAL || isDone) {
                  setStreamingMessage(accumulatedMessage);
                  lastUpdateTime = now;
                }
              }
              if (isDone) {
                if (accumulatedMessage) {
                  setMessages(prev => [...prev, { role: 'assistant', text: accumulatedMessage }]);
                }
                setStreamingId(null);
                setStreamingMessage(null);
              }
            } catch (callbackError) {
              console.error('Stream callback error:', callbackError);
              setStreamingId(null);
              setStreamingMessage(null);
            }
          };

          // è°ƒç”¨AIæœåŠ¡ï¼Œä½¿ç”¨æµå¼è¾“å‡º - AIæœåŠ¡ä¼šè‡ªåŠ¨å¤„ç†APIå¯†é’¥ç¼ºå¤±çš„æƒ…å†µ
          // æ·»åŠ è¶…æ—¶å¤„ç†
          const timeoutPromise = new Promise<void>((_, reject) => {
            setTimeout(() => reject(new Error('AIæœåŠ¡å“åº”è¶…æ—¶')), 30000); // 30ç§’è¶…æ—¶
          });
          
          await Promise.race([
            aiService.getSmartResponse(
              msgText, 
              knowledgeBase, 
              project.config.provider, 
              project.config.systemInstruction,
              {
                stream: true,
                callback: streamCallback,
                projectConfig: project.config // ä¼ é€’é¡¹ç›®é…ç½®
              }
            ),
            timeoutPromise
          ]);
        } catch (error) {
          console.error('AIæœåŠ¡è°ƒç”¨å¤±è´¥:', error);
          
          // æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºä¸åŒçš„ç”¨æˆ·å‹å¥½æç¤º
          let errorMessage = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚";
          
          if (error instanceof Error) {
            if (error.message === 'AIæœåŠ¡å“åº”è¶…æ—¶') {
              errorMessage = 'AIæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚';
            } else if (error.message.includes('429')) {
              errorMessage = "æœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•ã€‚";
            } else if (error.message.includes('network') || error.message.includes('fetch')) {
              errorMessage = "ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•ã€‚";
            } else {
              errorMessage = `æœåŠ¡é”™è¯¯: ${error.message}`;
            }
          }
          
          setMessages(prev => [...prev, { role: 'assistant', text: errorMessage }]);
          setStreamingId(null);
          setStreamingMessage(null);
        }
      }
    } catch (e) {
      console.error('æ¶ˆæ¯å¤„ç†å¤±è´¥:', e);
      setMessages(prev => [...prev, { role: 'assistant', text: 'æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚' }]);
      setStreamingId(null);
      setStreamingMessage(null);
    } finally {
      setIsTyping(false);
    }
  };

  const playTTS = async (text: string) => {
    try {
      // ç¡®ä¿ä½¿ç”¨ä¿å­˜çš„APIå¯†é’¥ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }
      
      const audioData = await aiService.generateSpeech(text, project.config.voiceName || 'tongtong', project.config.provider);
      if (audioData) {
        const audio = new Audio(`data:audio/wav;base64,${audioData}`);
        audio.play();
      } else {
        // ä¸æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œé™é»˜å¤„ç†
      }
    } catch (error) {
      console.error('TTSæ’­æ”¾å¤±è´¥:', error);
      // ä¸æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œé™é»˜å¤„ç†
    }
  };

  // è¯­éŸ³å¸¸é©»ç›‘å¬åŠŸèƒ½
  const toggleVoiceListening = async () => {
    if (isVoiceActive) {
      // å–æ¶ˆå¸¸é©»ç›‘å¬
      stopVoiceListening();
    } else {
      // å¼€å§‹å¸¸é©»ç›‘å¬
      startVoiceListening();
    }
  };

  const startVoiceListening = async () => {
    try {
      // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }
      
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      setIsVoiceActive(true);
      setIsRecording(false);

      // åˆ›å»ºéŸ³é¢‘åˆ†æå™¨ï¼Œç”¨äºæ£€æµ‹è¯­éŸ³æ´»åŠ¨
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      // æŒç»­åˆ†æéŸ³é¢‘
      const analyzeAudio = () => {
        if (!isVoiceActive) return;

        analyser.getByteFrequencyData(dataArray);
        
        // è®¡ç®—éŸ³é¢‘èƒ½é‡
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i];
        }
        const average = sum / bufferLength;

        // è¯­éŸ³é˜ˆå€¼
        const voiceThreshold = 50;
        const silenceThreshold = 30;

        if (average > voiceThreshold && !isRecording) {
          // æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³
          startRecording(stream);
        } else if (average < silenceThreshold && isRecording) {
          // æ£€æµ‹åˆ°é™éŸ³ï¼Œå¯åŠ¨é™éŸ³å®šæ—¶å™¨
          if (silenceTimer) {
            clearTimeout(silenceTimer);
          }
          const timer = setTimeout(() => {
            stopRecording();
          }, 1500); // 1.5ç§’é™éŸ³ååœæ­¢å½•éŸ³
          setSilenceTimer(timer);
        } else if (average > voiceThreshold && silenceTimer) {
          // é‡æ–°æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå–æ¶ˆé™éŸ³å®šæ—¶å™¨
          clearTimeout(silenceTimer);
          setSilenceTimer(null);
        }

        requestAnimationFrame(analyzeAudio);
      };

      analyzeAudio();
    } catch (error) {
      console.error('Failed to start voice listening:', error);
      setMessages(prev => [...prev, { role: 'assistant', text: 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®ã€‚' }]);
      setIsVoiceActive(false);
    }
  };

  const stopVoiceListening = () => {
    setIsVoiceActive(false);
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
    }
    if (silenceTimer) {
      clearTimeout(silenceTimer);
      setSilenceTimer(null);
    }
    setMediaRecorder(null);
    setAudioChunks([]);
    setIsRecording(false);
    setMessages(prev => [...prev, { role: 'assistant', text: 'è¯­éŸ³ç›‘å¬å·²å…³é—­ã€‚' }]);
  };

  const startRecording = (stream: MediaStream) => {
    const recorder = new MediaRecorder(stream);
    setMediaRecorder(recorder);
    setIsRecording(true);
    
    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        setAudioChunks(prev => [...prev, event.data]);
      }
    };
    
    recorder.onstop = async () => {
      if (audioChunks.length > 0) {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        await processAudioBlob(audioBlob);
      }
      setAudioChunks([]);
      setIsRecording(false);
    };
    
    recorder.start();
  };

  const stopRecording = () => {
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop();
    }
  };

  const processAudioBlob = async (audioBlob: Blob) => {
    try {
      // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }

      // è½¬æ¢ä¸ºbase64
      const reader = new FileReader();
      reader.onload = async () => {
        const base64Audio = (reader.result as string).split(',')[1];
        
        try {
          const recognizedText = await aiService.recognizeSpeech(base64Audio, project?.config.provider || 'zhipu');
          if (recognizedText) {
            handleSend(recognizedText);
          }
        } catch (error) {
          console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
          setMessages(prev => [...prev, { role: 'assistant', text: 'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•æˆ–ä½¿ç”¨æ–‡å­—è¾“å…¥ã€‚' }]);
        }
      };
      reader.readAsDataURL(audioBlob);
    } catch (error) {
      console.error('éŸ³é¢‘å¤„ç†å¤±è´¥:', error);
    }
  };

  // OCR ç›¸å…³æ–¹æ³•
  const showOcrMessage = (type: 'info' | 'success' | 'error', text: string) => {
    setOcrMessage({ type, text });
    setTimeout(() => setOcrMessage({ type: 'info', text: '' }), 3000);
  };

  const handleOcrImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      processOcrImage(file);
    }
  };
  
  const processOcrImage = async (file: File) => {
    try {
      setIsOcrProcessing(true);
      showOcrMessage('info', 'æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—...');
      
      // æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡
      const reader = new FileReader();
      reader.onload = (event) => {
        const imageUrl = event.target?.result as string;
        setOcrImage(imageUrl);
      };
      reader.readAsDataURL(file);
      
      // ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
      const savedApiKey = localStorage.getItem('zhipuApiKey');
      if (savedApiKey) {
        aiService.setZhipuApiKey(savedApiKey);
      }
      
      try {
        // è°ƒç”¨ OCR æœåŠ¡ - AIæœåŠ¡ä¼šè‡ªåŠ¨å¤„ç†APIå¯†é’¥ç¼ºå¤±çš„æƒ…å†µ
        const ocrResult = await aiService.recognizeHandwriting(file, {
          languageType: 'CHN_ENG',
          probability: true
        });
        
        if (ocrResult.status === 'succeeded') {
          const recognizedText = ocrResult.words_result
            .map((item: any) => item.words)
            .join('\n');
          
          setOcrResult(recognizedText);
          showOcrMessage('success', 'OCRè¯†åˆ«æˆåŠŸ');
          
          // å°†è¯†åˆ«ç»“æœå‘é€åˆ°èŠå¤©
          if (recognizedText) {
            handleSend(`OCRè¯†åˆ«ç»“æœ:\n${recognizedText}`);
          }
        } else {
          showOcrMessage('error', 'OCRè¯†åˆ«å¤±è´¥');
        }
      } catch (ocrError) {
        console.error('OCRè¯†åˆ«å¤±è´¥:', ocrError);
        // å¦‚æœOCRå¤±è´¥ï¼Œæä¾›åŸºç¡€çš„å›¾ç‰‡å¤„ç†ä¿¡æ¯
        setOcrResult('OCRè¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚\n\nè¯·æ‚¨ï¼š\n1. ç¡®ä¿å›¾ç‰‡æ¸…æ™°å¯è§\n2. æ–‡å­—å†…å®¹å®Œæ•´\n3. è”ç³»æŠ€æœ¯æ”¯æŒè·å¾—å¸®åŠ©\n\næŠ€æœ¯æ”¯æŒï¼š400-888-6666');
        showOcrMessage('info', 'OCRè¯†åˆ«æœåŠ¡éœ€è¦é…ç½®ï¼Œå·²æ˜¾ç¤ºåŸºç¡€ä¿¡æ¯');
        
        // å°†åŸºç¡€ä¿¡æ¯å‘é€åˆ°èŠå¤©
        handleSend('å›¾ç‰‡å·²ä¸Šä¼ ï¼ŒOCRè¯†åˆ«æœåŠ¡éœ€è¦é…ç½®ã€‚è¯·æè¿°å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›ç›¸åº”çš„å¸®åŠ©ã€‚');
      }
    } catch (error) {
      console.error('å›¾ç‰‡å¤„ç†å¤±è´¥:', error);
      showOcrMessage('error', 'å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•');
    } finally {
      setIsOcrProcessing(false);
    }
  };
  
  const clearOcrResults = () => {
    setOcrResult('');
    setOcrImage(null);
    if (ocrFileInputRef.current) {
      ocrFileInputRef.current.value = '';
    }
  };
  
  const openOcrFilePicker = () => {
    ocrFileInputRef.current?.click();
  };

  return (
    <div className="flex flex-col h-screen w-full max-w-full sm:max-w-lg mx-auto bg-[#12151b] shadow-2xl relative overflow-hidden font-sans">
      {/* Video chat interface */}
      {isVideoChatActive && (
        <div className="absolute inset-0 z-50 bg-[#0a0c10] flex flex-col">
          {/* Video chat header */}
          <header className="bg-[#0f1218]/80 backdrop-blur-3xl p-6 text-white shrink-0 border-b border-white/5 z-20">
            <div className="flex items-center justify-between">
              <div className="flex items-center gap-4">
                <div className="w-12 h-12 purple-gradient-btn rounded-2xl flex items-center justify-center">
                  <Sparkles size={24} />
                </div>
                <div>
                  <h1 className="font-black text-base sm:text-lg truncate max-w-[70%]">{project.name} - è§†é¢‘å®¢æœ</h1>
                  <div className="flex items-center gap-4 mt-2">
                    <div className="flex items-center gap-2">
                      <span className={`w-2 h-2 rounded-full ${isConnected ? 'bg-emerald-400 animate-pulse' : 'bg-red-500'}`}></span>
                      <span className="text-[10px] font-black uppercase tracking-widest">
                        {connectionStatus === 'connected' ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}
                      </span>
                    </div>
                    <div className="text-[10px] text-slate-400 font-black uppercase tracking-widest">
                      GLM-Realtime
                    </div>
                  </div>
                </div>
              </div>
              <button onClick={toggleVideoChat} className="p-4 sm:p-3 bg-white/5 border border-white/10 rounded-xl text-white">
                <X size={24} className="sm:size-5" />
              </button>
            </div>
          </header>

          {/* Video area */}
          <div className="flex-1 relative bg-black">
            <div className="absolute inset-0 flex items-center justify-center">
              {videoStream ? (
                <>
                  <video 
                    ref={videoRef} 
                    autoPlay 
                    playsInline 
                    className="w-full h-full object-cover"
                    onMouseDown={(e) => {
                      const pressTimer = setTimeout(async () => {
                        // é•¿æŒ‰æˆªå±é€»è¾‘
                        if (videoRef.current) {
                          const video = videoRef.current;
                          const canvas = document.createElement('canvas');
                          canvas.width = video.videoWidth;
                          canvas.height = video.videoHeight;
                          const ctx = canvas.getContext('2d');
                          if (ctx) {
                            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                            canvas.toBlob(async (blob) => {
                              if (blob) {
                                const file = new File([blob], 'screenshot.png', { type: 'image/png' });
                                // ä½¿ç”¨ç°æœ‰çš„OCRå¤„ç†å‡½æ•°
                                await processOcrImage(file);
                              }
                            });
                          }
                        }
                      }, 800);
                      // æ¸…é™¤å®šæ—¶å™¨
                      const clearTimer = () => clearTimeout(pressTimer);
                      if (videoRef.current) {
                        videoRef.current.onmouseup = clearTimer;
                        videoRef.current.onmouseleave = clearTimer;
                      }
                    }}
                  />
                  <canvas 
                    ref={canvasRef} 
                    className="absolute inset-0 w-full h-full"
                    width={1280}
                    height={720}
                  />
                </>
              ) : (
                <div className="text-center">
                  <div className="w-20 h-20 sm:w-24 sm:h-24 mx-auto mb-4 bg-white/10 rounded-full flex items-center justify-center">
                    <Video size={40} className="sm:size-12 text-violet-400" />
                  </div>
                  <p className="text-white text-base sm:text-lg font-medium">æ­£åœ¨åˆå§‹åŒ–è§†é¢‘...</p>
                </div>
              )}
            </div>
            
            {/* Bottom control bar */}
            <div className="absolute bottom-0 left-0 right-0 p-4 sm:p-6 bg-gradient-to-t from-black/80 to-transparent">
              <div className="flex items-center justify-between">
                {/* Video controls */}
                <div className="flex items-center gap-3">
                  <button 
                    onClick={toggleVideo} 
                    className={`p-4 sm:p-3 rounded-full ${isVideoOn ? 'bg-white/10 text-white' : 'bg-red-500/20 text-red-400'}`}
                  >
                    <Video size={24} className="sm:size-5" />
                  </button>
                  <button 
                    onClick={toggleAudio} 
                    className={`p-4 sm:p-3 rounded-full ${isAudioOn ? 'bg-white/10 text-white' : 'bg-red-500/20 text-red-400'}`}
                  >
                    <Mic size={24} className="sm:size-5" />
                  </button>
                  <button className="p-4 sm:p-3 bg-white/10 rounded-full text-white">
                    <Camera size={24} className="sm:size-5" />
                  </button>
                </div>
                
                {/* Annotation tools */}
                <div className="flex items-center gap-2">
                  <button 
                    onClick={() => addAnnotation('arrow')} 
                    className="p-3 sm:p-2 bg-white/10 rounded-lg text-white hover:bg-white/20"
                  >
                    <ArrowRight size={20} className="sm:size-4" />
                  </button>
                  <button 
                    onClick={() => addAnnotation('circle')} 
                    className="p-3 sm:p-2 bg-white/10 rounded-lg text-white hover:bg-white/20"
                  >
                    <Circle size={20} className="sm:size-4" />
                  </button>
                  <button 
                    onClick={() => addAnnotation('text', 'æ–‡æœ¬æ ‡æ³¨')} 
                    className="p-3 sm:p-2 bg-white/10 rounded-lg text-white hover:bg-white/20"
                  >
                    <Pencil size={20} className="sm:size-4" />
                  </button>
                  <button 
                    onClick={() => addAnnotation('highlight')} 
                    className="p-3 sm:p-2 bg-white/10 rounded-lg text-white hover:bg-white/20"
                  >
                    <Highlighter size={20} className="sm:size-4" />
                  </button>
                </div>
                
                {/* More controls */}
                <div className="flex items-center gap-3">
                  <button className="p-4 sm:p-3 bg-white/10 rounded-full text-white">
                    <Volume2 size={24} className="sm:size-5" />
                  </button>
                  <button className="p-4 sm:p-3 purple-gradient-btn rounded-full text-white">
                    <Video size={24} className="sm:size-5" />
                  </button>
                </div>
              </div>
            </div>
          </div>

          {/* Virtual human and chat area */}
          <div className="w-full h-52 sm:h-64 bg-gradient-to-b from-[#1a1d29] to-[#0f1218] flex flex-col">
            {/* Virtual human area */}
            <div className="h-40 sm:h-48 flex items-center justify-center relative overflow-hidden">
              <div className="absolute inset-0 opacity-20">
                <div className="w-full h-full bg-[radial-gradient(circle_at_center,_var(--tw-gradient-stops))] from-violet-500 via-transparent to-transparent"></div>
              </div>
              <div className="relative z-10 text-center">
                <div className="w-16 h-16 sm:w-20 sm:h-20 mx-auto mb-3 bg-gradient-to-br from-violet-500 to-purple-600 rounded-full flex items-center justify-center">
                  <Sparkles size={32} className="sm:size-10 text-white" />
                </div>
                <h3 className="text-white font-bold text-sm">æ™ºèƒ½åŠ©æ‰‹</h3>
                <p className="text-[9px] sm:text-[10px] text-emerald-400 font-black uppercase tracking-widest">
                  {avatarState.expression === 'neutral' ? 'å°±ç»ª' : 'å¯¹è¯ä¸­'}
                </p>
              </div>
            </div>
            
            {/* Chat input area */}
            <div className="p-4 border-t border-white/5">
              <div className="flex items-center gap-3">
                <div className="flex-1 relative">
                  <input 
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyDown={(e) => e.key === 'Enter' && !e.shiftKey && handleSend()}
                    placeholder="é—®æˆ‘å…³äºæ­¤äº§å“çš„é—®é¢˜..."
                    className="w-full bg-white/5 border border-white/10 px-4 py-2.5 sm:px-6 sm:py-3 rounded-xl text-base sm:text-sm text-white outline-none focus:ring-2 focus:ring-violet-500/20"
                  />
                  <button onClick={() => handleSend()} className="absolute right-2 top-1.5 p-3 sm:p-2 purple-gradient-btn text-white rounded-lg">
                    <Send size={20} className="sm:size-4" />
                  </button>
                </div>
              </div>
            </div>
          </div>
        </div>
      )}

      {/* Regular chat interface */}
      {!isVideoChatActive && (
        <>
          <header className="bg-[#0f1218]/80 backdrop-blur-3xl p-6 text-white shrink-0 border-b border-white/5 z-20">
            <div className="flex items-center justify-between mb-5">
              <div className="flex items-center gap-4">
                <div className="w-12 h-12 purple-gradient-btn rounded-2xl flex items-center justify-center">
                  <Sparkles size={24} />
                </div>
                <div>
                  <h1 className="font-black text-base sm:text-lg truncate max-w-[70%]">{project.name}</h1>
                  <p className="text-[9px] sm:text-[10px] text-emerald-400 font-black uppercase tracking-widest flex items-center gap-1">
                    <span className="w-1.5 h-1.5 sm:w-2 sm:h-2 bg-emerald-400 rounded-full animate-pulse"></span>
                    Expert Mode ä¸“å®¶æ¨¡å¼
                  </p>
                </div>
              </div>
              <div className="p-2.5 bg-white/5 rounded-xl">
                <Sparkles size={18} className="text-red-500" />
              </div>
            </div>
            
            {project.config.videoGuides.filter(v => v.status === 'approved' || !v.status).length > 0 && (
              <div className="flex gap-2 overflow-x-auto pb-1 no-scrollbar">
                {project.config.videoGuides
                  .filter(v => v.status === 'approved' || !v.status) // åªæ˜¾ç¤ºå·²é€šè¿‡å®¡æ ¸çš„è§†é¢‘ï¼Œå…¼å®¹æ—§æ•°æ®
                  .map(v => (
                    <button 
                      key={v.id}
                      onClick={() => setActiveVideo(v.url)}
                      className="flex items-center gap-2 bg-white/5 border border-white/10 px-3 py-2 rounded-xl text-[9px] sm:text-[10px] font-black uppercase tracking-widest text-slate-300 whitespace-nowrap min-w-max"
                    >
                      <PlayCircle size={14} className="sm:size-3.5 text-violet-500" /> {v.title}
                    </button>
                  ))
                }
              </div>
            )}
          </header>

          {activeVideo && (
            <div className="absolute inset-0 z-50 bg-black/95 flex flex-col items-center justify-center p-6">
              <button onClick={() => setActiveVideo(null)} className="absolute top-4 right-4 sm:top-8 sm:right-8 text-white p-3 bg-white/10 rounded-full"><X size={24} className="sm:size-7" /></button>
              <video src={activeVideo} controls autoPlay className="w-full max-w-full h-auto rounded-2xl sm:rounded-[2rem] shadow-2xl border border-white/10" />
            </div>
          )}

          {/* OCR æ¶ˆæ¯æç¤º */}
          {ocrMessage.text && (
            <div className={`mx-4 sm:mx-6 mt-4 p-3 rounded-lg flex items-center gap-2 ${
              ocrMessage.type === 'success' ? 'bg-green-900/30 text-green-400' :
              ocrMessage.type === 'error' ? 'bg-red-900/30 text-red-400' :
              'bg-blue-900/30 text-blue-400'
            }`}>
              {ocrMessage.type === 'success' && <CheckCircle size={16} />}
              {ocrMessage.type === 'error' && <AlertCircle size={16} />}
              {ocrMessage.type === 'info' && <FileText size={16} />}
              <span className="text-xs">{ocrMessage.text}</span>
            </div>
          )}
          
          {/* OCR ç»“æœæ˜¾ç¤º */}
          {ocrImage && (
            <div className="mx-4 sm:mx-6 my-4 p-3 sm:p-4 bg-white/5 rounded-xl sm:rounded-2xl border border-white/10">
              <div className="flex justify-between items-start mb-3">
                <h4 className="text-sm font-semibold text-white flex items-center gap-1">
                  <ImageIcon size={16} className="sm:size-3.5" />
                  OCR è¯†åˆ«ç»“æœ
                </h4>
                <button
                  onClick={clearOcrResults}
                  className="text-sm text-white/50 hover:text-white transition-colors p-1"
                >
                  <X size={16} className="sm:size-3.5" />
                </button>
              </div>
              <div className="mb-3">
                <img
                  src={ocrImage}
                  alt="OCR Image"
                  className="w-full max-h-32 object-contain bg-white/5 rounded-xl"
                />
              </div>
              <div>
                <p className="text-xs sm:text-sm text-white/80 whitespace-pre-line">
                  {ocrResult || 'è¯†åˆ«ä¸­...'}
                </p>
              </div>
            </div>
          )}
          
          <div ref={scrollRef} className="flex-1 overflow-y-auto p-4 sm:p-6 space-y-6 sm:space-y-8">
            {messages.map((m, i) => (
              <div key={i} className={`flex ${m.role === 'user' ? 'justify-end' : 'justify-start'} animate-in slide-in-from-bottom-2`}>
                <div className={`max-w-[85%] ${m.role === 'user' ? 'order-1' : 'order-2'}`}>
                  <div className={`p-4 sm:p-5 rounded-2xl sm:rounded-[2rem] shadow-xl text-base sm:text-sm leading-relaxed ${
                    m.role === 'user' ? 'bg-violet-600 text-white rounded-br-none' : 'bg-white/5 text-slate-100 rounded-bl-none border border-white/5'
                  }`}>
                    {m.image && <img src={m.image} className="rounded-2xl mb-4" />}
                    <p>{m.text}</p>
                  </div>
                  {m.role === 'assistant' && (
                    <div className="flex gap-4 mt-3 pl-1">
                      <button onClick={() => playTTS(m.text)} className="flex items-center gap-2 text-[9px] sm:text-[10px] font-black text-slate-500 uppercase tracking-widest hover:text-violet-400">
                        <Volume2 size={14} className="sm:size-3" /> Audio æ’­æ”¾è¯­éŸ³
                      </button>
                    </div>
                  )}
                </div>
              </div>
            ))}
            
            {/* Streaming message display */}
            {streamingMessage && (
              <div className="flex justify-start animate-in slide-in-from-bottom-2">
                <div className="max-w-[85%] order-2">
                  <div className="p-5 rounded-[2rem] shadow-xl text-sm leading-relaxed bg-white/5 text-slate-100 rounded-tl-none border border-white/5">
                    <p>{streamingMessage}</p>
                  </div>
                </div>
              </div>
            )}
            
            {isTyping && !streamingMessage && (
              <div className="flex gap-2 p-4 bg-white/5 w-fit rounded-2xl rounded-tl-none">
                <div className="w-2 h-2 sm:w-1.5 sm:h-1.5 bg-violet-500 rounded-full animate-bounce"></div>
                <div className="w-2 h-2 sm:w-1.5 sm:h-1.5 bg-violet-500 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                <div className="w-2 h-2 sm:w-1.5 sm:h-1.5 bg-violet-500 rounded-full animate-bounce" style={{animationDelay: '0.4s'}}></div>
              </div>
            )}
          </div>

          {/* æ‰‹æœºç«¯ä¼˜åŒ–ï¼šè¾“å…¥æ¡†å•ç‹¬ä¸€è¡Œ */}
          <div className="p-3 sm:p-4 bg-[#0f1218]/80 backdrop-blur-3xl border-t border-white/5">
            <input
              ref={ocrFileInputRef}
              type="file"
              accept="image/*"
              onChange={handleOcrImageUpload}
              className="hidden"
            />
            
            {/* åŠŸèƒ½æŒ‰é’®åŒº */}
            <div className="flex items-center justify-between mb-3">
              <div className="flex items-center gap-2">
                <div className="relative group">
                  <button 
                    onClick={() => fileInputRef.current?.click()} 
                    className="p-4 sm:p-3 bg-white/5 border border-white/10 rounded-xl text-violet-400"
                  >
                    <Camera size={24} className="sm:size-5" />
                  </button>
                  <div className="absolute -bottom-full left-1/2 transform -translate-x-1/2 mb-2 bg-white/10 backdrop-blur-xl border border-white/20 rounded-xl p-2 text-[10px] font-black text-white opacity-0 group-hover:opacity-100 transition-all whitespace-nowrap z-50">
                    ä¸Šä¼ å›¾ç‰‡
                  </div>
                </div>
                <button onClick={toggleVoiceListening} className={`p-4 sm:p-3 rounded-xl border ${isVoiceActive ? 'bg-red-500/20 border-red-500/30 text-red-400' : 'bg-white/5 border-white/10 text-violet-400'}`}>
                  <Mic size={24} className="sm:size-5" />
                </button>
                {project.config.videoChatEnabled && (
                  <button onClick={toggleVideoChat} className="p-4 sm:p-3 bg-white/5 border border-white/10 rounded-xl text-violet-400">
                    <Video size={24} className="sm:size-5" />
                  </button>
                )}

              </div>
            </div>
            
            {/* è¾“å…¥æ¡†å•ç‹¬ä¸€è¡Œ */}
            <div className="relative">
              <input 
                value={inputValue}
                onChange={(e) => setInputValue(e.target.value)}
                onKeyDown={(e) => e.key === 'Enter' && !e.shiftKey && handleSend()}
                placeholder="é—®æˆ‘å…³äºæ­¤äº§å“çš„é—®é¢˜..."
                className="w-full bg-white/5 border border-white/10 px-4 py-3 sm:px-5 sm:py-4 rounded-xl text-base sm:text-sm text-white outline-none focus:ring-2 focus:ring-violet-500/20 pr-16"
              />
              <button onClick={() => handleSend()} className="absolute right-2.5 top-2.5 p-3 sm:p-2 purple-gradient-btn text-white rounded-lg">
                <Send size={20} className="sm:size-5" />
              </button>
            </div>
            
            <input type="file" ref={fileInputRef} className="hidden" accept="image/*" onChange={(e) => {
              const f = e.target.files?.[0];
              if (f) {
                // åŒæ—¶å¤„ç†å›¾ç‰‡åˆ†æå’ŒOCR
                const r = new FileReader();
                r.onload = () => {
                  // å‘é€å›¾ç‰‡åˆ†æè¯·æ±‚
                  handleSend("åˆ†æç…§ç‰‡ Analyze photo", r.result as string);
                  // åŒæ—¶è¿›è¡ŒOCRå¤„ç†
                  processOcrImage(f);
                };
                r.readAsDataURL(f);
              }
            }} />
          </div>
        </>
      )}
    </div>
  );
};

export default UserPreview;