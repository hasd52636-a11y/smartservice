
import { KnowledgeItem, AIProvider } from "../types";

// æ™ºè°±AI APIé…ç½®
const ZHIPU_BASE_URL = '/api/zhipu';

// æ™ºè°±æ¨¡å‹ç±»å‹ - åŸºäºå®˜æ–¹APIæ–‡æ¡£
export enum ZhipuModel {
  // æ–‡æœ¬æ¨¡å‹
  GLM_4_7 = 'glm-4.7',
  GLM_4_7_FLASH = 'glm-4.7-flash', 
  GLM_4_7_FLASHX = 'glm-4.7-flashx',
  GLM_4_6 = 'glm-4.6',
  GLM_4_5_AIR = 'glm-4.5-air',
  GLM_4_5_AIRX = 'glm-4.5-airx',
  GLM_4_5_FLASH = 'glm-4.5-flash',
  
  // è§†è§‰æ¨¡å‹
  GLM_4_6V = 'glm-4.6v',
  GLM_4_6V_FLASH = 'glm-4.6v-flash',
  GLM_4_6V_FLASHX = 'glm-4.6v-flashx',
  GLM_4V_FLASH = 'glm-4v-flash',
  AUTOGLM_PHONE = 'autoglm-phone',
  GLM_4_1V_THINKING_FLASHX = 'glm-4.1v-thinking-flashx',
  GLM_4_1V_THINKING_FLASH = 'glm-4.1v-thinking-flash',
  
  // éŸ³é¢‘æ¨¡å‹
  GLM_4_VOICE = 'glm-4-voice',
  
  // è§’è‰²æ¨¡å‹
  CHARGLM_4 = 'charglm-4',
  EMOHAA = 'emohaa',
  
  // å…¶ä»–æ¨¡å‹
  GLM_REALTIME = 'glm-realtime-flash',
  EMBEDDING_3 = 'embedding-3',
  EMBEDDING_2 = 'embedding-2'
}

// å·¥å…·ç±»å‹æ¥å£
export interface FunctionTool {
  type: 'function';
  function: {
    name: string;
    description: string;
    parameters: {
      type: string;
      properties: Record<string, any>;
      required?: string[];
    };
  };
}

// æµå¼å›è°ƒç±»å‹
export type StreamCallback = (chunk: string, isDone: boolean, finishReason?: string) => void;

// GLM-Realtimeå›è°ƒç±»å‹
export type RealtimeCallback = (data: any, type: 'audio' | 'video' | 'text' | 'annotation' | 'status') => void;

// è™šæ‹ŸäººçŠ¶æ€æ¥å£
export interface AvatarState {
  expression: string;
  gesture: string;
  speech: string;
  mouthShape: string;
}

// æ ‡æ³¨æ¥å£
export interface Annotation {
  id: string;
  type: 'arrow' | 'circle' | 'text' | 'highlight';
  position: { x: number; y: number; z?: number };
  size: { width: number; height: number };
  content: string;
  color: string;
  timestamp: number;
}

export class AIService {
  private realtimeWebSocket: WebSocket | null = null;
  private realtimeCallbacks: RealtimeCallback[] = [];
  private streamId: string | null = null;
  private isRealtimeConnected: boolean = false;
  private zhipuApiKey: string = '';

  private async zhipuFetch(endpoint: string, body: any, isBinary: boolean = false) {
    try {
      if (!this.zhipuApiKey) {
        throw new Error('æ™ºè°±AI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·å…ˆé…ç½®APIå¯†é’¥');
      }

      const response = await fetch(`${ZHIPU_BASE_URL}${endpoint}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.zhipuApiKey}`,
        },
        body: JSON.stringify(body),
      });

      if (!response.ok) {
        let errorMessage = 'Zhipu API Error';
        try {
          const err = await response.json();
          errorMessage = err?.error?.message || err?.message || errorMessage;
        } catch (parseError) {
          console.error('Error parsing error response:', parseError);
        }
        throw new Error(`${errorMessage} (${response.status})`);
      }

      return isBinary ? response.arrayBuffer() : response.json();
    } catch (error) {
      console.error('Zhipu API request failed:', error);
      throw error;
    }
  }

  // æ™ºè°±æµå¼è¯·æ±‚
  private async zhipuStreamFetch(endpoint: string, body: any, callback: StreamCallback) {
    try {
      if (!this.zhipuApiKey) {
        throw new Error('æ™ºè°±AI APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·å…ˆé…ç½®APIå¯†é’¥');
      }

      const response = await fetch(`${ZHIPU_BASE_URL}${endpoint}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.zhipuApiKey}`,
        },
        body: JSON.stringify(body),
      });

      if (!response.ok) {
        let errorMessage = 'Zhipu API Error';
        try {
          const err = await response.json();
          errorMessage = err?.error?.message || err?.message || errorMessage;
        } catch (parseError) {
          console.error('Error parsing error response:', parseError);
        }
        throw new Error(`${errorMessage} (${response.status})`);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('No response body');
      }

      const decoder = new TextDecoder();
      let done = false;

      while (!done) {
        const { value, done: readerDone } = await reader.read();
        done = readerDone;
        
        if (value) {
          const chunk = decoder.decode(value, { stream: !done });
          const lines = chunk.split('\n');
          
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.substring(6);
              if (data === '[DONE]') {
                callback('', true, 'stop');
              } else {
                try {
                  const parsed = JSON.parse(data);
                  const content = parsed.choices[0]?.delta?.content || '';
                  if (content) {
                    callback(content, false);
                  }
                  if (parsed.choices[0]?.finish_reason) {
                    callback('', true, parsed.choices[0].finish_reason);
                  }
                } catch (error) {
                  console.error('Error parsing SSE chunk:', error);
                }
              }
            }
          }
        }
      }
    } catch (error) {
      console.error('Zhipu API stream request failed:', error);
      throw error;
    }
  }

  /**
   * Enhanced RAG Logic (Retrieval Augmented Generation)
   */
  private retrieveRelevantKnowledge(prompt: string, knowledge: KnowledgeItem[]): KnowledgeItem[] {
    const query = prompt.toLowerCase();
    
    // è®¡ç®—æ¯ä¸ªçŸ¥è¯†é¡¹çš„ç›¸å…³æ€§å¾—åˆ†
    const scoredItems = knowledge.map(item => {
      let score = 0;
      
      // æ ‡é¢˜åŒ¹é…å¾—åˆ†ï¼ˆæƒé‡æœ€é«˜ï¼‰
      if (item.title.toLowerCase().includes(query)) {
        score += 3.0;
      }
      
      // å†…å®¹åŒ¹é…å¾—åˆ†
      if (item.content.toLowerCase().includes(query)) {
        score += 2.0;
      }
      
      // æ ‡ç­¾åŒ¹é…å¾—åˆ†
      if (item.tags && item.tags.some(t => t.toLowerCase().includes(query))) {
        score += 1.5;
      }
      
      // å…³é”®è¯åŒ¹é…ï¼ˆç®€å•çš„åˆ†è¯åŒ¹é…ï¼‰
      const queryWords = query.split(/\s+/).filter(word => word.length > 1);
      const itemText = `${item.title} ${item.content}`.toLowerCase();
      
      queryWords.forEach(word => {
        if (itemText.includes(word)) {
          score += 0.5;
        }
      });
      
      return { item, score };
    });
    
    // æŒ‰å¾—åˆ†æ’åºå¹¶è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„
    return scoredItems
      .filter(item => item.score > 0) // åªè¿”å›æœ‰åŒ¹é…çš„
      .sort((a, b) => b.score - a.score) // æŒ‰å¾—åˆ†é™åº
      .slice(0, 5) // æœ€å¤šè¿”å›5ä¸ª
      .map(item => item.item); // æå–çŸ¥è¯†é¡¹
  }

  async getSmartResponse(prompt: string, knowledge: KnowledgeItem[], provider: AIProvider, systemInstruction: string, options?: {
    stream?: boolean;
    callback?: StreamCallback;
    model?: string;
    temperature?: number;
    maxTokens?: number;
    tools?: FunctionTool[];
    responseFormat?: { type: 'text' | 'json_object' };
  }) {
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if (!this.zhipuApiKey) {
      const mockResponse = this.generateMockResponse(prompt, knowledge);
      
      if (options?.stream && options?.callback) {
        // æ¨¡æ‹Ÿæµå¼è¾“å‡º
        const words = mockResponse.split('');
        let index = 0;
        const streamInterval = setInterval(() => {
          if (index < words.length) {
            options.callback!(words[index], false);
            index++;
          } else {
            options.callback!('', true, 'stop');
            clearInterval(streamInterval);
          }
        }, 50); // æ¯50msè¾“å‡ºä¸€ä¸ªå­—ç¬¦ï¼Œæ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
        return '';
      } else {
        return mockResponse;
      }
    }

    try {
      // 1. å‘é‡åŒ–ç”¨æˆ·æŸ¥è¯¢
      const queryEmbedding = await this.createEmbedding(prompt, {
        model: ZhipuModel.EMBEDDING_3,
        dimensions: 768
      });
      
      // 2. å‘é‡åŒ–çŸ¥è¯†åº“æ–‡æ¡£ï¼ˆå¦‚æœå°šæœªå‘é‡åŒ–ï¼‰
      const vectorizedKnowledge = await Promise.all(
        knowledge.map(async (item) => {
          if (!item.embedding) {
            const embeddingResult = await this.createEmbedding(item.content, {
              model: ZhipuModel.EMBEDDING_3,
              dimensions: 768
            });
            return { ...item, embedding: embeddingResult.data[0].embedding };
          }
          return item;
        })
      );
      
      // 3. è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
      const relevantItems = vectorizedKnowledge
        .map(item => ({
          item,
          score: this.cosineSimilarity(
            queryEmbedding.data[0].embedding,
            item.embedding!
          )
        }))
        .filter(item => item.score > 0.3) // é˜ˆå€¼è¿‡æ»¤
        .sort((a, b) => b.score - a.score)
        .slice(0, 5) // æœ€å¤šè¿”å›5ä¸ªç›¸å…³æ–‡æ¡£
        .map(item => item.item);
      
      // 4. æ„å»ºä¸Šä¸‹æ–‡
      const context = relevantItems.length > 0 
        ? relevantItems.map((item, index) => `[Knowledge Item ${index + 1}: ${item.title}]\n${item.content}`).join('\n\n')
        : "No direct match in custom knowledge base. When no relevant information is found, you must clearly state that you don't have specific information about the topic and suggest contacting human customer service.";

      const fullPrompt = `You are a product support AI specialized in providing accurate answers based on the provided knowledge base.\n\nIMPORTANT GUIDELINES:\n1. **Strictly use only the information provided in the context** for your answers
2. **Do not invent or assume any information** not explicitly stated in the context
3. **Cite the source** of your information by referencing the knowledge item number
4. **If no relevant information is found**, clearly state that you don't have specific information about the topic\n5. **Be concise and direct** in your responses\n6. **Maintain a professional and helpful tone**\n\nContext:\n${context}\n\nUser Question: ${prompt}`;

      // ä»…ä½¿ç”¨æ™ºè°±AIå®ç°
      const requestBody = {
        model: options?.model || 'glm-4.7',
        messages: [
          { role: 'system', content: systemInstruction },
          { role: 'user', content: fullPrompt }
        ],
        temperature: options?.temperature || 0.1,
        max_tokens: options?.maxTokens || 1024,
        stream: options?.stream || false,
        tools: options?.tools,
        response_format: options?.responseFormat
      };

      if (options?.stream && options?.callback) {
        await this.zhipuStreamFetch('/chat/completions', requestBody, options.callback);
        return '';
      } else {
        const data = await this.zhipuFetch('/chat/completions', requestBody);
        return data.choices[0].message.content;
      }
    } catch (error) {
      console.error('å‘é‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯æ£€ç´¢:', error);
      
      // å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿå“åº”
      if (error instanceof Error && (error.message.includes('API key') || error.message.includes('401'))) {
        const mockResponse = this.generateMockResponse(prompt, knowledge);
        
        if (options?.stream && options?.callback) {
          // æ¨¡æ‹Ÿæµå¼è¾“å‡º
          const words = mockResponse.split('');
          let index = 0;
          const streamInterval = setInterval(() => {
            if (index < words.length) {
              options.callback!(words[index], false);
              index++;
            } else {
              options.callback!('', true, 'stop');
              clearInterval(streamInterval);
            }
          }, 50);
          return '';
        } else {
          return mockResponse;
        }
      }
      
      // å›é€€åˆ°ä¼ ç»Ÿå…³é”®è¯æ£€ç´¢
      const relevantItems = this.retrieveRelevantKnowledge(prompt, knowledge);
      const context = relevantItems.length > 0 
        ? relevantItems.map((item, index) => `[Knowledge Item ${index + 1}: ${item.title}]\n${item.content}`).join('\n\n')
        : "No direct match in custom knowledge base. When no relevant information is found, you must clearly state that you don't have specific information about the topic and suggest contacting human customer service.";

      const fullPrompt = `You are a product support AI specialized in providing accurate answers based on the provided knowledge base.\n\nIMPORTANT GUIDELINES:\n1. **Strictly use only the information provided in the context** for your answers
2. **Do not invent or assume any information** not explicitly stated in the context
3. **Cite the source** of your information by referencing the knowledge item number
4. **If no relevant information is found**, clearly state that you don't have specific information about the topic\n5. **Be concise and direct** in your responses\n6. **Maintain a professional and helpful tone**\n\nContext:\n${context}\n\nUser Question: ${prompt}`;

      const requestBody = {
        model: options?.model || 'glm-4.7',
        messages: [
          { role: 'system', content: systemInstruction },
          { role: 'user', content: fullPrompt }
        ],
        temperature: options?.temperature || 0.1,
        max_tokens: options?.maxTokens || 1024,
        stream: options?.stream || false,
        tools: options?.tools,
        response_format: options?.responseFormat
      };

      if (options?.stream && options?.callback) {
        await this.zhipuStreamFetch('/chat/completions', requestBody, options.callback);
        return '';
      } else {
        const data = await this.zhipuFetch('/chat/completions', requestBody);
        return data.choices[0].message.content;
      }
    }
  }

  // æ™ºè°±æ¨¡å‹å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ–‡ä»¶ï¼‰
  async analyzeMultimodal(content: any[], provider: AIProvider, options?: {
    model?: string;
    temperature?: number;
    maxTokens?: number;
  }) {
    // ä»…ä½¿ç”¨æ™ºè°±AIå®ç°
    const data = await this.zhipuFetch('/chat/completions', {
      model: options?.model || 'glm-4.6v',
      messages: [{
        role: 'user',
        content: content
      }],
      temperature: options?.temperature || 0.1,
      max_tokens: options?.maxTokens || 1024
    });
    return data.choices[0].message.content;
  }

  // æ™ºè°±æ¨¡å‹å·¥å…·è°ƒç”¨
  async callTool(functionName: string, args: any, provider: AIProvider) {
    // ä»…ä½¿ç”¨æ™ºè°±AIå®ç°
    const data = await this.zhipuFetch('/chat/completions', {
      model: 'glm-4.7',
      messages: [{
        role: 'tool',
        content: JSON.stringify(args),
        tool_call_id: `tool_${Date.now()}`
      }],
      temperature: 0.1
    });
    return data.choices[0].message.content;
  }

  // æ™ºè°±æ¨¡å‹è¯­éŸ³è¯†åˆ«
  async recognizeSpeech(audioData: string, provider: AIProvider): Promise<string | undefined> {
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if (!this.zhipuApiKey) {
      console.log('No API key available, using mock speech recognition');
      return this.generateMockSpeechRecognition();
    }

    if (provider === AIProvider.ZHIPU) {
      try {
        const data = await this.zhipuFetch('/chat/completions', {
          model: 'glm-4-voice',
          messages: [{
            role: 'user',
            content: [
              { type: 'input_audio', input_audio: {
                data: audioData,
                format: 'wav'
              }}
            ]
          }],
          temperature: 0.1
        });
        return data.choices[0].message.content;
      } catch (e) {
        console.error("Zhipu Speech Recognition Failed", e);
        return this.generateMockSpeechRecognition();
      }
    }

    return this.generateMockSpeechRecognition();
  }

  // æµ‹è¯•æ™ºè°±APIè¿æ¥
  async testZhipuConnection(): Promise<{ success: boolean; message: string }> {
    try {
      const data = await this.zhipuFetch('/chat/completions', {
        model: 'glm-4.7',
        messages: [
          { role: 'user', content: 'ping' }
        ],
        temperature: 0.1,
        max_tokens: 10
      });
      return { 
        success: true, 
        message: `Connected to Zhipu AI (${data.model})` 
      };
    } catch (error) {
      return { 
        success: false, 
        message: error instanceof Error ? error.message : 'Connection failed' 
      };
    }
  }

  async analyzeInstallation(imageBuffer: string, visionPrompt: string, provider: AIProvider) {
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if (!this.zhipuApiKey) {
      console.log('No API key available, using mock image analysis');
      return this.generateMockImageAnalysis(visionPrompt);
    }

    try {
      // ä»…ä½¿ç”¨æ™ºè°±AIå®ç°
      const data = await this.zhipuFetch('/chat/completions', {
        model: 'glm-4.6v',
        messages: [{
          role: 'user',
          content: [
            { type: 'text', text: visionPrompt },
            { type: 'image_url', image_url: { url: imageBuffer } }
          ]
        }]
      });
      return data.choices[0].message.content;
    } catch (error) {
      console.error('Image analysis failed, using mock response:', error);
      return this.generateMockImageAnalysis(visionPrompt);
    }
  }

  async generateSpeech(text: string, voiceName: string, provider: AIProvider): Promise<string | undefined> {
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if (!this.zhipuApiKey) {
      console.log('No API key available, TTS not available');
      return undefined;
    }

    // ä»…ä½¿ç”¨æ™ºè°±AIå®ç°
    try {
      const buffer = await this.zhipuFetch('/audio/speech', {
        model: 'glm-tts',
        input: text,
        voice: voiceName || 'tongtong',
        response_format: 'wav'
      }, true);
      
      const uint8 = new Uint8Array(buffer as ArrayBuffer);
      let binary = '';
      for (let i = 0; i < uint8.byteLength; i++) binary += String.fromCharCode(uint8[i]);
      return window.btoa(binary);
    } catch (e) {
      console.error("Zhipu TTS Failed", e);
      return undefined;
    }
  }

  async generateVideoGuide(prompt: string, provider: AIProvider, imageUrl?: string) {
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    const key = this.getZhipuApiKey();
    if (!key) {
      throw new Error('No Zhipu API key provided');
    }
    
    try {
      console.log('Generating video guide with prompt:', prompt);
      
      // æ³¨æ„ï¼šç”±äºCogVideoX-3 APIéœ€è¦åç«¯æœåŠ¡æ”¯æŒ
      // è¿™é‡Œä½¿ç”¨å¤šæ¨¡æ€APIç”Ÿæˆè§†é¢‘è„šæœ¬ï¼Œç„¶åè¿”å›ç¤ºä¾‹è§†é¢‘
      // å®é™…éƒ¨ç½²æ—¶éœ€è¦å®ç°åç«¯æœåŠ¡è°ƒç”¨CogVideoX-3 API
      
      // ç”Ÿæˆè§†é¢‘è„šæœ¬
      const videoScript = await this.zhipuFetch('/chat/completions', {
        model: 'glm-4.7',
        messages: [
          {
            role: 'system',
            content: 'You are a professional video script writer. Create a detailed script for a product installation video based on the given prompt.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 1024
      });
      
      console.log('Video script generated successfully');
      
      // æ¨¡æ‹Ÿè§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼ˆå®é™…éƒ¨ç½²æ—¶æ›¿æ¢ä¸ºçœŸå®çš„CogVideoX-3 APIè°ƒç”¨ï¼‰
      console.log('Simulating video generation with CogVideoX-3...');
      
      // æ³¨æ„ï¼šå®é™…çš„CogVideoX-3 APIè°ƒç”¨éœ€è¦åç«¯æœåŠ¡
      // å‰ç«¯ç›´æ¥è°ƒç”¨ä¼šæš´éœ²APIå¯†é’¥ï¼Œä¸å®‰å…¨
      // ä»¥ä¸‹æ˜¯åç«¯æœåŠ¡çš„å‚è€ƒå®ç°ï¼š
      /*
      const response = await fetch('https://open.bigmodel.cn/api/paas/v4/videos/generations', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${key}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'cogvideox-3',
          prompt: prompt,
          image_url: imageUrl,
          quality: 'quality',
          with_audio: true,
          size: '1920x1080',
          fps: 30
        })
      });
      
      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error.message || 'Video generation failed');
      }
      
      const result = await response.json();
      // è½®è¯¢è·å–è§†é¢‘ç”Ÿæˆç»“æœ
      const videoResult = await this.pollVideoGeneration(result.id, key);
      return {
        url: videoResult.video_url,
        status: 'approved',
        title: prompt.substring(0, 50),
        description: prompt,
        type: 'ai',
        metadata: {
          script: videoScript.choices[0].message.content,
          duration: 60,
          resolution: '1920x1080',
          format: 'mp4'
        }
      };
      */
      
      // è¿”å›ç¤ºä¾‹è§†é¢‘ä¿¡æ¯ï¼ˆå®é™…éƒ¨ç½²æ—¶æ›¿æ¢ä¸ºçœŸå®çš„è§†é¢‘ç”ŸæˆæœåŠ¡ï¼‰
      return {
        url: "https://cdn.bigmodel.cn/static/platform/videos/doc_solutions/Realtime-%E5%94%B1%E6%AD%8C.m4v",
        status: 'pending',
        title: prompt.substring(0, 50) + (prompt.length > 50 ? '...' : ''),
        description: prompt,
        type: 'ai',
        createdAt: new Date().toISOString(),
        metadata: {
          script: videoScript.choices[0].message.content,
          duration: 60,
          resolution: '1920x1080',
          format: 'mp4',
          generatedBy: 'CogVideoX-3'
        }
      };
    } catch (error) {
      console.error('Error generating video guide:', error);
      throw error;
    }
  }
  
  // è½®è¯¢è§†é¢‘ç”Ÿæˆç»“æœï¼ˆå®é™…éƒ¨ç½²æ—¶ä½¿ç”¨ï¼‰
  private async pollVideoGeneration(videoId: string, apiKey: string): Promise<any> {
    const pollInterval = 3000; // æ¯3ç§’è½®è¯¢ä¸€æ¬¡
    const maxAttempts = 30; // æœ€å¤šè½®è¯¢30æ¬¡ï¼ˆ90ç§’ï¼‰
    
    for (let attempt = 0; attempt < maxAttempts; attempt++) {
      const response = await fetch(`https://open.bigmodel.cn/api/paas/v4/videos/${videoId}`, {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      });
      
      if (!response.ok) {
        throw new Error('Failed to poll video generation status');
      }
      
      const result = await response.json();
      
      if (result.status === 'succeeded') {
        return result;
      } else if (result.status === 'failed') {
        throw new Error(result.error.message || 'Video generation failed');
      }
      
      // ç­‰å¾…ä¸‹ä¸€æ¬¡è½®è¯¢
      await new Promise(resolve => setTimeout(resolve, pollInterval));
    }
    
    throw new Error('Video generation timed out');
  }

  // GLM-Realtimeè¿æ¥ç®¡ç†
  async connectToRealtime(callback: RealtimeCallback): Promise<boolean> {
    try {
      const key = this.getZhipuApiKey();
      
      // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
      if (!key) {
        console.error('GLM-Realtime connection failed: No API key provided');
        callback({ error: 'ç¼ºå°‘APIå¯†é’¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜' }, 'status');
        return false;
      }
      
      const endpoint = `wss://open.bigmodel.cn/api/paas/v4/realtime?model=${ZhipuModel.GLM_REALTIME}`;
      
      console.log('Connecting to GLM-Realtime:', endpoint);
      this.realtimeWebSocket = new WebSocket(endpoint);
      this.realtimeCallbacks.push(callback);
      
      let connectionResolved = false;
      
      return new Promise((resolve) => {
        this.realtimeWebSocket!.onopen = () => {
          console.log('GLM-Realtime WebSocket connected');
          
          // å‘é€è®¤è¯æ¶ˆæ¯
          try {
            const authMessage = JSON.stringify({
              type: 'auth',
              data: {
                token: key
              }
            });
            console.log('Sending auth message...');
            this.realtimeWebSocket?.send(authMessage);
          } catch (error) {
            console.error('Error sending auth message:', error);
            callback({ error: 'è®¤è¯æ¶ˆæ¯å‘é€å¤±è´¥' }, 'status');
            resolve(false);
          }
        };
        
        this.realtimeWebSocket!.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            console.log('Received GLM-Realtime message:', data.type);
            
            // å¤„ç†è®¤è¯å“åº”
            if (data.type === 'auth' && data.data) {
              if (data.data.status === 'success') {
                console.log('GLM-Realtime authentication successful');
                this.isRealtimeConnected = true;
                callback({ status: 'connected' }, 'status');
                if (!connectionResolved) {
                  connectionResolved = true;
                  resolve(true);
                }
              } else if (data.data.status === 'error') {
                console.error('GLM-Realtime authentication failed:', data.data.message);
                callback({ error: `è®¤è¯å¤±è´¥: ${data.data.message}` }, 'status');
                if (!connectionResolved) {
                  connectionResolved = true;
                  resolve(false);
                }
              }
            }
            
            // å¤„ç†å…¶ä»–æ¶ˆæ¯ç±»å‹
            switch (data.type) {
              case 'audio':
                callback(data.data, 'audio');
                break;
              case 'video':
                callback(data.data, 'video');
                break;
              case 'text':
                callback(data.data, 'text');
                break;
              case 'annotation':
                callback(data.data, 'annotation');
                break;
              case 'status':
                callback(data.data, 'status');
                break;
              case 'error':
                console.error('GLM-Realtime error:', data.data);
                callback({ error: data.data }, 'status');
                break;
              case 'response.content_part.done':
                callback({ ...data, type: 'content_part_done' }, 'text');
                break;
              case 'response.function_call_arguments.done':
                callback({ ...data, type: 'function_call_done', function_name: data.name, function_arguments: data.arguments }, 'text');
                break;
              case 'response.function_call.simple_browser':
                callback(data, 'text');
                break;
              case 'response.text.delta':
                callback(data, 'text');
                break;
              case 'response.text.done':
                callback(data, 'text');
                break;
              case 'response.audio_transcript.delta':
                callback(data, 'text');
                break;
              case 'response.audio_transcript.done':
                callback(data, 'text');
                break;
              case 'response.audio.delta':
                callback(data, 'audio');
                break;
              case 'response.audio.done':
                callback(data, 'audio');
                break;
              case 'response.created':
                callback(data, 'status');
                break;
              case 'response.cancelled':
                callback(data, 'status');
                break;
              case 'response.done':
                callback(data, 'status');
                break;
              case 'rate_limits.updated':
                callback(data, 'status');
                break;
              case 'heartbeat':
                // å¿½ç•¥å¿ƒè·³æ¶ˆæ¯ï¼Œé¿å…è¿‡å¤šæ—¥å¿—
                break;
              default:
                console.log('Unhandled GLM-Realtime message type:', data.type);
            }
          } catch (error) {
            console.error('Error parsing realtime message:', error);
          }
        };
        
        this.realtimeWebSocket!.onclose = (event) => {
          console.log('GLM-Realtime WebSocket closed:', event.code, event.reason);
          this.isRealtimeConnected = false;
          callback({ status: 'disconnected' }, 'status');
          if (!connectionResolved) {
            connectionResolved = true;
            resolve(false);
          }
        };
        
        this.realtimeWebSocket!.onerror = (error) => {
          console.error('GLM-Realtime WebSocket error:', error);
          callback({ error: 'WebSocketè¿æ¥é”™è¯¯' }, 'status');
          if (!connectionResolved) {
            connectionResolved = true;
            resolve(false);
          }
        };
        
        // è®¾ç½®è¿æ¥è¶…æ—¶
        setTimeout(() => {
          if (!connectionResolved) {
            connectionResolved = true;
            console.error('GLM-Realtime connection timeout');
            callback({ error: 'è¿æ¥è¶…æ—¶' }, 'status');
            this.realtimeWebSocket?.close();
            resolve(false);
          }
        }, 10000); // 10ç§’è¶…æ—¶
      });
    } catch (error) {
      console.error('Failed to connect to GLM-Realtime:', error);
      callback({ error: 'è¿æ¥å¤±è´¥' }, 'status');
      return false;
    }
  }

  // å‘é€è§†é¢‘å¸§åˆ°GLM-Realtime
  sendVideoFrame(frame: Blob | string) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'video',
        data: {
          frame: typeof frame === 'string' ? frame : frame,
          format: typeof frame === 'string' ? 'base64' : 'blob'
        }
      }));
    } catch (error) {
      console.error('Error sending video frame:', error);
    }
  }

  // å‘é€éŸ³é¢‘æ•°æ®åˆ°GLM-Realtime
  sendAudioData(audio: Blob | string) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'audio',
        data: {
          audio: typeof audio === 'string' ? audio : audio,
          format: typeof audio === 'string' ? 'base64' : 'blob'
        }
      }));
    } catch (error) {
      console.error('Error sending audio data:', error);
    }
  }

  // å‘é€æ–‡æœ¬æ¶ˆæ¯åˆ°GLM-Realtime
  sendTextMessage(text: string) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'text',
        data: {
          text: text
        }
      }));
    } catch (error) {
      console.error('Error sending text message:', error);
    }
  }

  // æ§åˆ¶è™šæ‹Ÿäºº
  controlAvatar(avatarState: Partial<AvatarState>) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'avatar',
        data: avatarState
      }));
    } catch (error) {
      console.error('Error controlling avatar:', error);
    }
  }

  // æ·»åŠ æ ‡æ³¨
  addAnnotation(annotation: Omit<Annotation, 'id' | 'timestamp'>) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      const fullAnnotation = {
        ...annotation,
        id: `annot_${Date.now()}`,
        timestamp: Date.now()
      };
      
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'annotation',
        data: {
          action: 'add',
          annotation: fullAnnotation
        }
      }));
      
      return fullAnnotation;
    } catch (error) {
      console.error('Error adding annotation:', error);
      return null;
    }
  }

  // æ›´æ–°æ ‡æ³¨
  updateAnnotation(id: string, updates: Partial<Annotation>) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'annotation',
        data: {
          action: 'update',
          id: id,
          updates: updates
        }
      }));
    } catch (error) {
      console.error('Error updating annotation:', error);
    }
  }

  // åˆ é™¤æ ‡æ³¨
  deleteAnnotation(id: string) {
    if (!this.isRealtimeConnected || !this.realtimeWebSocket) {
      console.warn('GLM-Realtime not connected');
      return;
    }
    
    try {
      this.realtimeWebSocket.send(JSON.stringify({
        type: 'annotation',
        data: {
          action: 'delete',
          id: id
        }
      }));
    } catch (error) {
      console.error('Error deleting annotation:', error);
    }
  }

  // æ–­å¼€GLM-Realtimeè¿æ¥
  disconnectFromRealtime() {
    if (this.realtimeWebSocket) {
      this.realtimeWebSocket.close();
      this.realtimeWebSocket = null;
      this.isRealtimeConnected = false;
      this.realtimeCallbacks = [];
      this.streamId = null;
      console.log('GLM-Realtime disconnected');
    }
  }

  // æ£€æŸ¥GLM-Realtimeè¿æ¥çŠ¶æ€
  isRealtimeConnectionActive(): boolean {
    return this.isRealtimeConnected && this.realtimeWebSocket !== null;
  }

  // å‘é‡æ¨¡å‹ï¼šåˆ›å»ºæ–‡æœ¬åµŒå…¥
  async createEmbedding(texts: string | string[], options?: {
    model?: string;
    dimensions?: number;
  }): Promise<any> {
    const requestBody = {
      model: options?.model || ZhipuModel.EMBEDDING_3,
      input: Array.isArray(texts) ? texts : [texts],
      dimensions: options?.dimensions
    };

    const data = await this.zhipuFetch('/embeddings', requestBody);
    return data;
  }

  // è®¡ç®—å‘é‡ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
  cosineSimilarity(vec1: number[], vec2: number[]): number {
    const dotProduct = vec1.reduce((sum, a, i) => sum + a * vec2[i], 0);
    const magnitude1 = Math.sqrt(vec1.reduce((sum, a) => sum + a * a, 0));
    const magnitude2 = Math.sqrt(vec2.reduce((sum, a) => sum + a * a, 0));
    
    if (magnitude1 === 0 || magnitude2 === 0) {
      return 0;
    }
    
    return dotProduct / (magnitude1 * magnitude2);
  }

  // ç”Ÿæˆæ¨¡æ‹Ÿå“åº”ï¼ˆå½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨ï¼‰
  private generateMockResponse(prompt: string, knowledge: KnowledgeItem[]): string {
    // ç¡®ä¿promptæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå¤„ç†å„ç§å¯èƒ½çš„è¾“å…¥
    let promptStr = '';
    if (typeof prompt === 'string') {
      promptStr = prompt;
    } else if (prompt && typeof prompt === 'object' && 'target' in prompt) {
      // å¦‚æœæ˜¯äº‹ä»¶å¯¹è±¡ï¼Œå°è¯•è·å–å€¼
      promptStr = (prompt as any).target?.value || '';
    } else {
      promptStr = String(prompt || '');
    }
    
    const lowerPrompt = promptStr.toLowerCase();
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹
    const relevantItems = this.retrieveRelevantKnowledge(promptStr, knowledge);
    
    if (relevantItems.length > 0) {
      // å¦‚æœæœ‰ç›¸å…³çŸ¥è¯†ï¼ŒåŸºäºçŸ¥è¯†åº“å†…å®¹ç”Ÿæˆå“åº”
      const firstItem = relevantItems[0];
      return `æ ¹æ®äº§å“çŸ¥è¯†åº“ï¼Œå…³äº"${promptStr}"çš„ä¿¡æ¯ï¼š\n\n${firstItem.content.substring(0, 200)}${firstItem.content.length > 200 ? '...' : ''}\n\nå¦‚éœ€æ›´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è”ç³»ä¸­æ’åˆ›ä¸–æŠ€æœ¯æ”¯æŒï¼š400-888-6666`;
    }
    
    // å¸¸è§é—®é¢˜çš„æ¨¡æ‹Ÿå“åº”
    if (lowerPrompt.includes('å®‰è£…') || lowerPrompt.includes('install')) {
      return 'å…³äºäº§å“å®‰è£…ï¼Œå»ºè®®æ‚¨ï¼š\n\n1. ä»”ç»†é˜…è¯»äº§å“è¯´æ˜ä¹¦\n2. ç¡®ä¿å®‰è£…ç¯å¢ƒç¬¦åˆè¦æ±‚\n3. æŒ‰ç…§æ­¥éª¤é€ä¸€æ“ä½œ\n4. å¦‚é‡é—®é¢˜è¯·æ‹ç…§å‘é€ç»™æˆ‘åˆ†æ\n\nå¦‚éœ€ä¸“ä¸šæŠ€æœ¯æ”¯æŒï¼Œè¯·è”ç³»ï¼š400-888-6666';
    }
    
    if (lowerPrompt.includes('æ•…éšœ') || lowerPrompt.includes('é—®é¢˜') || lowerPrompt.includes('error')) {
      return 'é‡åˆ°äº§å“æ•…éšœæ—¶ï¼Œè¯·ï¼š\n\n1. æè¿°å…·ä½“æ•…éšœç°è±¡\n2. æä¾›äº§å“å‹å·ä¿¡æ¯\n3. ä¸Šä¼ æ•…éšœç°åœºç…§ç‰‡\n4. è¯´æ˜ä½¿ç”¨ç¯å¢ƒå’Œæ“ä½œæ­¥éª¤\n\næˆ‘ä¼šåŸºäºè¿™äº›ä¿¡æ¯ä¸ºæ‚¨æä¾›è§£å†³æ–¹æ¡ˆã€‚å¦‚éœ€äººå·¥å®¢æœï¼Œè¯·æ‹¨æ‰“ï¼š400-888-6666';
    }
    
    if (lowerPrompt.includes('ä½¿ç”¨') || lowerPrompt.includes('æ“ä½œ') || lowerPrompt.includes('how')) {
      return 'å…³äºäº§å“ä½¿ç”¨æ–¹æ³•ï¼š\n\n1. è¯·å…ˆæŸ¥çœ‹äº§å“è¯´æ˜ä¹¦\n2. ç¡®ä¿æ­£ç¡®è¿æ¥å’Œè®¾ç½®\n3. æŒ‰ç…§æ“ä½œæŒ‡å—è¿›è¡Œ\n4. æ³¨æ„å®‰å…¨äº‹é¡¹\n\nå¦‚æœ‰å…·ä½“æ“ä½œé—®é¢˜ï¼Œè¯·è¯¦ç»†æè¿°æˆ–ä¸Šä¼ å›¾ç‰‡ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›æŒ‡å¯¼ã€‚æŠ€æœ¯æ”¯æŒçƒ­çº¿ï¼š400-888-6666';
    }
    
    if (lowerPrompt.includes('ç»´æŠ¤') || lowerPrompt.includes('ä¿å…»') || lowerPrompt.includes('maintenance')) {
      return 'äº§å“ç»´æŠ¤ä¿å…»å»ºè®®ï¼š\n\n1. å®šæœŸæ¸…æ´äº§å“è¡¨é¢\n2. æ£€æŸ¥è¿æ¥éƒ¨ä»¶æ˜¯å¦æ¾åŠ¨\n3. é¿å…åœ¨æ¶åŠ£ç¯å¢ƒä¸­ä½¿ç”¨\n4. æŒ‰ç…§ä¿å…»å‘¨æœŸè¿›è¡Œç»´æŠ¤\n\nå…·ä½“ç»´æŠ¤æ–¹æ³•è¯·å‚è€ƒè¯´æ˜ä¹¦ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒï¼š400-888-6666';
    }
    
    // é»˜è®¤å“åº”
    return `æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å”®åå®¢æœåŠ©æ‰‹ã€‚\n\nå…³äºæ‚¨çš„é—®é¢˜"${promptStr}"ï¼Œæˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥ä¸ºæ‚¨æä¾›å‡†ç¡®çš„è§£ç­”ã€‚è¯·æ‚¨ï¼š\n\n1. è¯¦ç»†æè¿°é—®é¢˜æƒ…å†µ\n2. æä¾›äº§å“å‹å·\n3. ä¸Šä¼ ç›¸å…³å›¾ç‰‡\n\nè¿™æ ·æˆ‘èƒ½æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚éœ€äººå·¥å®¢æœï¼Œè¯·æ‹¨æ‰“ï¼š400-888-6666\n\nå®˜ç½‘ï¼šwww.aivirtualservice.com`;
  }

  // æ¨¡æ‹Ÿå›¾ç‰‡åˆ†æï¼ˆå½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨ï¼‰
  private generateMockImageAnalysis(prompt: string): string {
    return `å›¾ç‰‡åˆ†æåŠŸèƒ½éœ€è¦AIæœåŠ¡æ”¯æŒã€‚\n\næˆ‘çœ‹åˆ°æ‚¨ä¸Šä¼ äº†å›¾ç‰‡ï¼Œä½†ç›®å‰AIè§†è§‰åˆ†ææœåŠ¡éœ€è¦é…ç½®ã€‚\n\nè¯·æ‚¨ï¼š\n1. è¯¦ç»†æè¿°å›¾ç‰‡ä¸­çš„é—®é¢˜\n2. è¯´æ˜äº§å“å‹å·å’Œä½¿ç”¨æƒ…å†µ\n3. è”ç³»æŠ€æœ¯æ”¯æŒè·å¾—ä¸“ä¸šåˆ†æ\n\nä¸­æ’åˆ›ä¸–æŠ€æœ¯æ”¯æŒï¼š\nğŸ“ 400-888-6666\nğŸŒ www.aivirtualservice.com\n\næˆ‘ä»¬çš„æŠ€æœ¯ä¸“å®¶ä¼šä¸ºæ‚¨æä¾›è¯¦ç»†çš„å›¾ç‰‡åˆ†æå’Œè§£å†³æ–¹æ¡ˆã€‚`;
  }

  // æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ï¼ˆå½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨ï¼‰
  private generateMockSpeechRecognition(): string {
    return 'è¯­éŸ³è¯†åˆ«åŠŸèƒ½éœ€è¦AIæœåŠ¡æ”¯æŒï¼Œè¯·ä½¿ç”¨æ–‡å­—è¾“å…¥æˆ–è”ç³»äººå·¥å®¢æœï¼š400-888-6666';
  }

  // OCRæœåŠ¡ï¼šæ‰‹å†™ä½“è¯†åˆ«
  async recognizeHandwriting(imageFile: File, options?: {
    languageType?: string;
    probability?: boolean;
  }): Promise<any> {
    const key = this.getZhipuApiKey();
    
    // æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if (!key) {
      throw new Error('No Zhipu API key provided');
    }
    
    try {
      const formData = new FormData();
      formData.append('file', imageFile);
      formData.append('tool_type', 'hand_write');
      formData.append('language_type', options?.languageType || 'CHN_ENG');
      formData.append('probability', String(options?.probability || false));

      console.log('Sending OCR request to Vercel Serverless Function...');
      const response = await fetch('/api/ocr', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        let errorMessage = 'OCR API Error';
        try {
          const err = await response.json();
          errorMessage = err?.error?.message || err?.message || errorMessage;
        } catch (parseError) {
          console.error('Error parsing OCR error response:', parseError);
        }
        throw new Error(`${errorMessage} (${response.status})`);
      }

      const result = await response.json();
      console.log('OCR response:', result);
      return result;
    } catch (error) {
      console.error('OCR request failed:', error);
      throw error;
    }
  }

  // OCRæœåŠ¡ï¼šé€šç”¨æ–‡æœ¬è¯†åˆ«ï¼ˆæ”¯æŒå°åˆ·ä½“ï¼‰
  async recognizeOCR(imageFile: File, options?: {
    languageType?: string;
    probability?: boolean;
  }): Promise<any> {
    return this.recognizeHandwriting(imageFile, options);
  }

  // è®¾ç½®æ™ºè°±APIå¯†é’¥
  setZhipuApiKey(apiKey: string) {
    this.zhipuApiKey = apiKey;
    // åŒæ—¶ä¿å­˜åˆ°localStorageï¼Œä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
    localStorage.setItem('zhipuApiKey', apiKey);
  }

  // è·å–æ™ºè°±APIå¯†é’¥
  getZhipuApiKey(): string {
    // ä¼˜å…ˆä½¿ç”¨å†…å­˜ä¸­çš„å¯†é’¥
    if (this.zhipuApiKey) {
      return this.zhipuApiKey;
    }
    // ä»localStorageè·å–
    const savedKey = localStorage.getItem('zhipuApiKey');
    if (savedKey) {
      this.zhipuApiKey = savedKey;
      return savedKey;
    }
    // ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆå¦‚æœåœ¨æµè§ˆå™¨ç¯å¢ƒä¸­å¯ç”¨ï¼‰
    if (typeof window !== 'undefined' && (window as any).ZHIPU_API_KEY) {
      this.zhipuApiKey = (window as any).ZHIPU_API_KEY;
      return this.zhipuApiKey;
    }
    return '';
  }
}


export const aiService = new AIService();
